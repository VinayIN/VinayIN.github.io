# Binay Kumar Pradhan — Machine Learning Engineer • AI Engineer • Data Scientist

Contact: +49 163 850 4970 • bpradhan.asli@gmail.com • www.linkedin.com/in/i-binay • binaypradhan.com • Cottbus, Germany

Summary
Machine Learning Engineer / AI Engineer / Data Scientist specializing in ML system design, speech recognition (ASR), model compression (pruning/quantization/distillation), and reinforcement learning (RL). I build end-to-end ML systems in Python and Rust (PyTorch, TorchAudio, AWS SageMaker), taking models from data to deployment with MLOps, CI/CD, and observability. Passionate about reproducible, ethical AI. Seeking roles where I can drive measurable impact on latency, accuracy, cost, and reliability.

Core competencies (ATS-optimized)
- ML System Design, MLOps, ML Engineering, AI Engineering, Data Science, ASR (speech recognition), NLP, Computer Vision
- Model Compression: pruning, quantization, knowledge distillation, model size reduction, CPU/GPU inference optimization
- Reinforcement Learning: policy design, reward shaping, simulation, PPO/DQN, optimization under constraints
- Data/Platform: ETL/ELT, feature stores, streaming/batch pipelines, observability/logging, model registry
- Languages/Tools: Python, Rust, PyTorch, TorchAudio, scikit-learn, NumPy, Pandas, Docker, Jenkins, Git, AWS (SageMaker, Lambda)

Specializations
- System Design for ML platforms: training/inference orchestration, cost/performance optimization, reliability and SLOs
- Speech Recognition (ASR): audio preprocessing, feature extraction, streaming and batch inference, WER/CER evaluation
- Model Compression: pruning/quantization/distillation to cut latency and footprint while maintaining accuracy
- Reinforcement Learning: operations optimization via policy learning, simulation-driven evaluation

Experience
Brandenburgische Technische Universität Cottbus–Senftenberg (BTU) — Research Assistant (Jun 2023 – Mar 2025) • Cottbus, Germany
- S (context): Research chairs in Programming Languages/Compiler Construction and Neuroadaptive HCI needed reproducible workflows, tooling, and optimization approaches.
- T (responsibility): Build data tooling, evaluate optimization methods (RL vs CP), support EEG/eye-tracking research, and publish reusable software.
- A (actions):
  - Built Python ETL to extract test-case data from Java subroutines; added static/dynamic analysis hooks; created interactive Plotly dashboards.
  - Designed reward functions and training loops (PPO/DQN) to benchmark RL policies vs. constraint programming for stockyard management.
  - Co-designed EEG experiment protocols; implemented calibration paradigms; built real-time and offline analysis notebooks (MNE/Torch).
  - Authored and published pyETA-toolbox to PyPI with real-time fixation detection, saccade metrics, and device validation utilities.
  - Prototyped ASR pipelines (TorchAudio) with resampling, spectrogram/CMVN, and WER/CER evaluation for batch/streaming inference.
- R (results, XYZ):
  - Reduced researcher debugging/insight turnaround by [20–40%] via ETL + dashboards.
  - Improved simulated time-cost objective by [10–15%] vs. CP baseline by applying RL with domain-shaped rewards.
  - Shortened EEG experiment calibration/analysis cycles by [25–35%] through standardized protocols/notebooks.
  - Cut eye-tracker study setup time by [30–50%] through pyETA-toolbox, enabling reproducible PassiveBCI workflows.
  - Standardized ASR preprocessing/evaluation, improving comparability across models/datasets (WER/CER) by [X%].

Wolkus Technology Solutions (Fasal) — AI Data Engineer II (Jun 2022 – Sep 2022) • Bangalore, India
- S: Rapidly evolving production ML workflows required scalable training/deployment and cloud migration.
- T: Implement MLOps (SageMaker Pipelines), migrate datamart GCP→AWS, optimize serverless latency, and improve observability.
- A: Built train/validate/register/promote pipelines; integrated model registry and automated approvals; migrated via IaC (CloudFormation/Terraform) with data-quality monitoring; optimized Lambda (right-sizing, layers, provisioned concurrency); authored fasal-logger (PyPI) with structured logging and correlation IDs.
- R (XYZ):
  - Cut manual release steps by [60–80%] and improved lineage/traceability.
  - Reduced Lambda cold-starts by [30–50%], lowering p95 latency by [20–35%].
  - Increased reliability and lowered maintenance via migration and monitoring; reduced mean time to resolution (MTTR) by [X%].

Myelin Foundry — Software Engineer II (Oct 2021 – Mar 2022) • Bangalore, India
- S: Edge in-car AI assistant required real-time perception under tight compute constraints.
- T: Ship gesture, facial emotion, and object detection features to Android with stable FPS and low latency.
- A: Integrated MediaPipe face/hand meshes; trained facial emotion models (FER+/AffectNet) with TFLite quantization; retrained YOLOv5 for selected classes; worked with Android team to bridge Python→Java and optimize JNI paths.
- R (XYZ): Achieved [~30 FPS] on target devices; reduced model size/latency via quantization/pruning by [X%] while maintaining acceptable accuracy (Δ≤[Y%]).

Utopia India (Prometheus Group) — Data Science Engineer (Jul 2019 – Oct 2021) • Bangalore, India
- S: Enterprise data cleansing (4C) needed higher throughput, accuracy, and maintainability across diverse documents.
- T: Improve extraction accuracy, reduce latency, and enable scalable processing; introduce CI/CD and cost-efficient compute.
- A: Built Streamlit/Flask data apps and REST APIs; combined ML parsers with regex fallbacks and consensus voting; implemented embedding-based entity mapping with spell correction and similar-term retrieval; designed template-based PDF segmentation; introduced Jenkins CI and AWS Spot compute; automated master-data migrations with audit logs; delivered training/KT sessions.
- R (XYZ):
  - Increased data-quality throughput by [2–3x] and reduced manual QA hours.
  - Delivered ~85% field-filling accuracy and ~15x throughput over legacy Excel/rules.
  - Reduced parsing failures by [X%] and cut build/test cycle time by [Y%]; lowered compute costs via Spot by [Z%].

Utopia India — Machine Learning Intern (Jan 2019 – Jul 2019) • Bangalore, India
- S/T: Standardize text mapping and improve batch processing reliability.
- A: Built hybrid text-matching using pre-trained vectors + custom embeddings, fuzzy logic, set relations; refactored standardization tool into data-driven architecture; orchestrated Makefile-based batch runs.
- R: Increased mapping accuracy and stability; enabled consistent batch processing for delivery teams.

Institute for Development and Research in Banking Technology (IDRBT) — Research Intern (May 2018 – Jul 2018) • Hyderabad, India
- S/T: Low-resource, mixed-script POS tagging needed curated data and baselines.
- A: Crawled and labeled Hindi/Bengali code-mixed Twitter data; assisted in POS tagging workflows, error analysis, and manuscript.
- R: Dataset/embeddings contributed to ACM TALLIP publication; enabled reproducible training/evaluation.

Education
- M.Sc. Artificial Intelligence (EQF 7), BTU Cottbus–Senftenberg, Germany (Oct 2022 – Present)
  Focus: System Design for ML, Speech Recognition (ASR), Model Compression (Pruning/Quantization/Distillation), Reinforcement Learning, Neuroadaptive HCI, MLOps
- B.Tech. Information Technology (EQF 7), IIIT Bhubaneswar, India (2015 – 2019)
  Thesis: Unstructured text to Structured text mapping | Final grade: 2.8

Publications
- Bhattu, Nunna, Somayajulu, Pradhan (2020). Improving Code-mixed POS Tagging Using Code-mixed Embeddings. ACM TALLIP 19(4): Article 50, 31 pages.

Honors & Awards
- Best Idea — Dell Codefest 2017; Smart India Hackathon 2018 (Software) Finalist; RangManch 3rd Best Performer; SPOT Award; GEM Award

Skills (ATS keywords repeated)
- Languages: Python, Rust, Bash
- ML/AI: PyTorch, TorchAudio, scikit-learn, NumPy, Pandas, Matplotlib/Seaborn, Transformers (BERT/GPT), YOLOv5
- MLOps/Cloud: AWS SageMaker, AWS Lambda, Docker, Jenkins, Git, CI/CD, Model Registry, Experiment Tracking, Observability/Logging
- Domains: Speech Recognition (ASR), Model Compression (Pruning/Quantization/Distillation), Reinforcement Learning, NLP, Computer Vision, Time Series, Edge AI (Android), Neuroadaptive HCI (EEG/Eye-Tracking)
- Data/Systems: ETL/ELT, Feature Stores, Streaming/Batch Pipelines, REST/GraphQL APIs, Microservices, Performance Optimization, Provisioned Concurrency

Selected Projects & Open Source
- pyETA-toolbox (PyPI): Real-time fixation detection and eye-tracker validation for PassiveBCI; reduced study setup by [30–50%]. How: streaming buffers, thresholded fixation detection (I-DT/I-VT style), validation reports.
- fasal-logger (PyPI): Structured logging for consistent observability; lowered MTTR and improved traceability. How: correlation IDs, JSON formatters, env-aware configs, CI checks.

Profile Highlights (for LinkedIn)
- Headline: Machine Learning Engineer • AI Engineer • Data Scientist | System Design for ML | ASR | Model Pruning/Compression | RL | Python/Rust | MLOps (SageMaker/PyTorch)
- About (XYZ): I design and ship ML systems (X) that reduce latency/cost and improve reliability (Y) by combining Python/Rust services, model compression (pruning/quantization/distillation), and AWS SageMaker MLOps (Z).

ATS Keyword Bank (include in profile/skills to increase match)
- Machine Learning Engineer, AI Engineer, Data Scientist, MLOps, ML Engineering, ML System Design, ASR, Speech Recognition, Model Pruning, Quantization, Knowledge Distillation, Reinforcement Learning, PPO, DQN, Python, Rust, PyTorch, TorchAudio, AWS SageMaker, AWS Lambda, CI/CD, Model Registry, Experiment Tracking, Observability, Logging, Feature Store, ETL, ELT, Streaming, Batch, Docker, Jenkins, Git, NLP, Computer Vision, Edge AI, Android, EEG, Eye-Tracking, PassiveBCI, WER, CER

Notes for validation
- Replace bracketed metrics [like this] with actual values you’re comfortable publishing (accuracy %, latency reductions, cost savings, FPS, dataset sizes, p95/p99 latency).
