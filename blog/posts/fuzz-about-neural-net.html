<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Fuzz about neural nets</title>
  <meta name="description" content="Although neural nets have been with us since 1940's but somehow their usability is mostly recognised in this decades.">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta property="og:title" content="Fuzz about neural nets">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://wezn.github.io/blog/posts/fuzz-about-neural-net">
  <meta property="og:description" content="Although neural nets have been with us since 1940's but somehow their usability is mostly recognised in this decades.">
  <meta property="og:site_name" content="ARTICLES">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:url" content="https://wezn.github.io/blog/posts/fuzz-about-neural-net">
  <meta name="twitter:title" content="Fuzz about neural nets">
  <meta name="twitter:description" content="Although neural nets have been with us since 1940's but somehow their usability is mostly recognised in this decades.">

  
    <meta property="og:image" content="https://wezn.github.io/blog/assets/og-image-ee46bbc61b334e821e81534b1fd43f3fee6f020ec174b3c2114445695fd48c01.jpg">
    <meta name="twitter:image" content="https://wezn.github.io/blog/assets/og-image-ee46bbc61b334e821e81534b1fd43f3fee6f020ec174b3c2114445695fd48c01.jpg">
  

  

  
    <link rel="icon" type="image/x-icon" href="/blog/assets/favicon-light-a98c41efc5ed9fcc06ac664c9e2f7a9b3c3b2e0a52357d221fe382f6f4abc8fc.ico">
    <link rel="apple-touch-icon" href="/blog/assets/apple-touch-icon-light-87d1f2a3a19b1500e5c1626a0492025ca5f7f97d24540dc5900288e92112925a.png">
    <link rel="stylesheet" type="text/css" href="/blog/assets/light-b34f12b58415aa3a5f6cf5f4caec8a9f2971a5aba876b1956e66ddb8dc92581f.css">
  
</head>

<body>
  <main>
    <div class="grid grid-centered">
      <div class="grid-cell">
        
  <ul class="header-links">
        
      <li>
        <a href="https://wezn.github.io" title="About me">
          <svg xmlns="http://www.w3.org/2000/svg" class="icon-about">
  <use href="/blog/assets/about-ecf154b571ab8034ae00aeed91a3b7ad68db80b46d958753ad6216c919486e88.svg#icon-about" xlink:href="/blog/assets/about-ecf154b571ab8034ae00aeed91a3b7ad68db80b46d958753ad6216c919486e88.svg#icon-about"></use>
</svg>
 About me
        </a>
      </li>
    
  </ul>


<nav class="header-nav scrollappear">
  <a href="/blog/" class="header-logo" title="ARTICLES">ARTICLES</a>
  <ul class="header-links">
    
    
      <li>
        <a href="https://github.com/VinayIN/" rel="noreferrer noopener" target="_blank" title="GitHub">
          <svg xmlns="http://www.w3.org/2000/svg" class="icon-github">
  <use href="/blog/assets/github-094f81040819f34343ee6ffff0980f17e2807b08b595eaaf66ae3554934fd78d.svg#icon-github" xlink:href="/blog/assets/github-094f81040819f34343ee6ffff0980f17e2807b08b595eaaf66ae3554934fd78d.svg#icon-github"></use>
</svg>

        </a>
      </li>
    
    
      <li>
        <a href="https://www.linkedin.com/in/i-binay/" rel="noreferrer noopener" target="_blank" title="LinkedIn">
          <svg xmlns="http://www.w3.org/2000/svg" class="icon-linkedin">
  <use href="/blog/assets/linkedin-cdc5c107044324a3dfbea2e9ead15873f8dee304c37d73a046988956b706256e.svg#icon-linkedin" xlink:href="/blog/assets/linkedin-cdc5c107044324a3dfbea2e9ead15873f8dee304c37d73a046988956b706256e.svg#icon-linkedin"></use>
</svg>

        </a>
      </li>
    
    
      <li>
        <a href="https://www.facebook.com/binay.pradhan.1996" rel="noreferrer noopener" target="_blank" title="Facebook">
          <svg xmlns="http://www.w3.org/2000/svg" class="icon-facebook">
  <use href="/blog/assets/facebook-72c99b26d37bee65607720abb23d26b44ef30cca1187f98b0d9305be1230b1bf.svg#icon-facebook" xlink:href="/blog/assets/facebook-72c99b26d37bee65607720abb23d26b44ef30cca1187f98b0d9305be1230b1bf.svg#icon-facebook"></use>
</svg>

        </a>
      </li>
    
    
    
    
    
    
    
    
    
    
      <li>
        <a href="https://instagram.com/i_binay/" rel="noreferrer noopener" target="_blank" title="Instagram">
          <svg xmlns="http://www.w3.org/2000/svg" class="icon-instagram">
  <use href="/blog/assets/instagram-37f85bc75b43ecc4c114d9a46f846327fe13c5893787c6afbcfef9d30d58bd9e.svg#icon-instagram" xlink:href="/blog/assets/instagram-37f85bc75b43ecc4c114d9a46f846327fe13c5893787c6afbcfef9d30d58bd9e.svg#icon-instagram"></use>
</svg>

        </a>
      </li>
    
    
    
    
    
    
    
    
    
    
      <li>
        <a href="mailto:pradhan.binay@outlook.com" title="Email">
          <svg xmlns="http://www.w3.org/2000/svg" class="icon-email">
  <use href="/blog/assets/email-782473193bf750036fdb90e8daa075508a20509d01854c09f3237c144a3f0601.svg#icon-email" xlink:href="/blog/assets/email-782473193bf750036fdb90e8daa075508a20509d01854c09f3237c144a3f0601.svg#icon-email"></use>
</svg>

        </a>
      </li>
    
    
  </ul>
</nav>

        <article class="article scrollappear">
          <header class="article-header">
            <h1>Fuzz about neural nets</h1>
            <p>Although neural nets have been with us since 1940's but somehow their usability is mostly recognised in this decades.</p>
            <div class="article-list-footer">
              <span class="article-list-date">
                June 25, 2018
              </span>
              <span class="article-list-divider">-</span>
              <span class="article-list-minutes">
                
                
                  3 minute read
                
              </span>
              <span class="article-list-divider">-</span>
              <div class="article-list-tags">
                
                  <a href="/blog/tag/Deep Learning">Deep Learning</a>
                
                  <a href="/blog/tag/Machine Learning">Machine Learning</a>
                
              </div>
            </div>
          </header>

          <div class="article-content">
            <p>The history of Neural network starts from 1943, when neurophysiologist Warren McCulloch and mathematician Walter Pitts wrote a <a href="https://doi.org/10.1007/BF02478259">paper</a> on how neurons might work being inspired with the biological neuron unit. Rest we might have heared about Hebb network, Perceptron, Adaline &amp; Madaline, Kohonen self-organizing map… etc and the list continues. Their approaches to using neural network with variations led to solving categories of problems.</p>

<p><em>Artificial Neural Network</em> has been a computation tool used by many in the domain of  Machine Learning where their is involvement of complex features and somehow at end, It all follows to <em>Deep Learning</em> problem set. <strong>Ian Goodfellow</strong>, <strong>Yoshua Bengio</strong> and <strong>Aaron Courville</strong> in their book <a href="https://www.deeplearningbook.org">Deep Learning</a> put forward their view of the AI contrast to the early days, where it was viewed to rapidly tackle and solve problems that are intellectually difficult for human beings but relatively straight- forward for computers. Today, the challenge is to solve the tasks that are easy for people to perform but hard for people to describe formally—problems that we solve intuitively, that feel automatic, like recognizing spoken words or faces in images.</p>

<p>To understand how neural nets use the feature set to adjust the parameter, tune hyperparameters, and come at decision for the input signals assume a situation very commonly analysed in <em>Deep Learning</em> <strong>“Boston house pricing”</strong>, Where one has to predict the price of the house depending on various features given as problem set.</p>

<p>If its done without neural net, the code for predicting the price follows as such:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>	<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>
    <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegresion</span>
    <span class="n">boston</span><span class="o">=</span><span class="n">load_boston</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="n">boston</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="c">#split the dataset</span>
    <span class="n">X</span><span class="o">=</span><span class="n">boston</span><span class="p">[</span><span class="s">"data"</span><span class="p">]</span>
    <span class="n">Y</span><span class="o">=</span><span class="n">boston</span><span class="p">[</span><span class="s">"target"</span><span class="p">]</span>
    <span class="n">train</span><span class="o">=</span><span class="n">X</span><span class="p">[:</span><span class="mi">500</span><span class="p">][:]</span>
    <span class="n">train_labels</span><span class="o">=</span><span class="n">Y</span><span class="p">[:</span><span class="mi">500</span><span class="p">]</span>
    <span class="n">test</span><span class="o">=</span><span class="n">X</span><span class="p">[</span><span class="o">-</span><span class="mi">6</span><span class="p">:][:]</span>
    <span class="n">test_labels</span><span class="o">=</span><span class="n">Y</span><span class="p">[</span><span class="o">-</span><span class="mi">6</span><span class="p">:]</span>

	<span class="c">#fit and train the linear regression model</span>
    <span class="n">reg</span><span class="o">=</span><span class="n">LinearRegression</span><span class="p">(</span><span class="n">fit_intercept</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">,</span><span class="n">train_labels</span><span class="p">)</span>
    <span class="n">pred</span><span class="o">=</span><span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>

	<span class="c">#find the score</span>
    <span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">test</span><span class="p">,</span><span class="n">test_labels</span><span class="p">)</span>
</code></pre></div></div>

<p>Without using neural net a simple linear regression model stated above doesn’t gives a satisfactory $R^2$ Score, Unless its hyperparameters are set according to the dataset. If the same situation is build upon a simple architecture of Linear regression neural network model.  An appreciable improvement and even a possibility for good $\displaystyle R^2 \approx 0$ is expected and this is totally taken care by neural nets if proper architecture is laid out.</p>

<h2 id="then-what-the-heck-does-neural-nets-do">Then what the heck does neural nets do?</h2>
<p>Considering the architecture of network, If a signal is able to trigger a threshold value ‘<em>$\theta$</em>’ then it propagates to next next layer of the network till output is generated. Here is a simple sketch introducing the idea that are considered when neural networks are used for any applications.</p>
<center><iframe width="50%" height="312" src="https://www.youtube.com/embed/w9OFiOaTFs8" frameborder="0" allowfullscreen=""></iframe></center>

<p>The model of ANN are specified by the three basic entities namely:</p>
<ol>
  <li>the model’s synaptic interconnections;</li>
  <li>the training or learning rules adopted for updating and adjusting the connection weights;</li>
  <li>their activation functions.</li>
</ol>

<p>Using multiple neural layers to represent the complex hierarchy of concepts so as to learn comlicated concepts by building them on simplier concepts is the characteristerization of deep learning. The quintessential example of a deep learning model is the feedforward deep network or multilayer perceptron (MLP), And it starts with a general equation: <strong>$Y=\sum_i^n (W_i * X_i) + b$</strong>. Adjusting <strong>weights</strong>, <strong>hyperparameters</strong> and <strong>optimization</strong> are the spices that adds flavour to the recipe on the network. These neural networks acts as a magical computational tools for complex feature sets depending on the weight values acheived after no. of <em>epochs</em>.</p>

<p>So this is what the neural networks basically does. There are many works of other researches that explains the mathematical view of neural networks. These are a set of concepts that has been a fascinating area for every AI researcher due to its usuability in intutitive problems. Feel free to reach me in case you find out more about the “<strong>nets</strong>”, untill then keep exploring.</p>

          </div>
          <div class="article-share">
            
            
            <a href="https://twitter.com/home?status=Fuzz+about+neural+nets%20-%20https://wezn.github.io/blog/posts/fuzz-about-neural-net" title="Share on Twitter" rel="noreferrer noopener" target="_blank">
              <svg viewBox="0 0 512 512"><path d="M492 109.5c-17.4 7.7-36 12.9-55.6 15.3 20-12 35.4-31 42.6-53.6 -18.7 11.1-39.4 19.2-61.5 23.5C399.8 75.8 374.6 64 346.8 64c-53.5 0-96.8 43.4-96.8 96.9 0 7.6 0.8 15 2.5 22.1 -80.5-4-151.9-42.6-199.6-101.3 -8.3 14.3-13.1 31-13.1 48.7 0 33.6 17.2 63.3 43.2 80.7C67 210.7 52 206.3 39 199c0 0.4 0 0.8 0 1.2 0 47 33.4 86.1 77.7 95 -8.1 2.2-16.7 3.4-25.5 3.4 -6.2 0-12.3-0.6-18.2-1.8 12.3 38.5 48.1 66.5 90.5 67.3 -33.1 26-74.9 41.5-120.3 41.5 -7.8 0-15.5-0.5-23.1-1.4C62.8 432 113.7 448 168.3 448 346.6 448 444 300.3 444 172.2c0-4.2-0.1-8.4-0.3-12.5C462.6 146 479 129 492 109.5z"/></svg>
            </a>
            <a href="https://www.facebook.com/sharer/sharer.php?u=https://wezn.github.io/blog/posts/fuzz-about-neural-net" title="Share on Facebook" rel="noreferrer noopener" target="_blank">
              <svg viewBox="0 0 512 512"><path d="M288 192v-38.1c0-17.2 3.8-25.9 30.5-25.9H352V64h-55.9c-68.5 0-91.1 31.4-91.1 85.3V192h-45v64h45v192h83V256h56.4l7.6-64H288z"/></svg>
            </a>
            <a href="https://plus.google.com/share?url=https://wezn.github.io/blog/posts/fuzz-about-neural-net" title="Share on Google+" rel="noreferrer noopener" target="_blank">
              <svg viewBox="0 0 128 128"><path d="M40.7 55.9v16.1c0 0 15.6 0 22 0C59.2 82.5 53.8 88.2 40.7 88.2c-13.3 0-23.7-10.8-23.7-24.2s10.4-24.2 23.7-24.2c7.1 0 11.6 2.5 15.8 5.9 3.3-3.3 3.1-3.8 11.6-11.9 -7.2-6.6-16.8-10.6-27.4-10.6C18.2 23.3 0 41.5 0 64c0 22.5 18.2 40.7 40.7 40.7 33.6 0 41.8-29.3 39-48.8H40.7zM113.9 56.7V42.6h-10.1v14.1H89.4v10.1h14.5v14.5h10.1V66.8H128V56.7H113.9z"/></svg>
            </a>
          </div>
<!-- 
           -->
        </article>
        <footer class="footer scrollappear">
  <p>
    Any queries regarding any article is appreciated. Please reach
    <a href="https://wezn.github.io" target="_blank">Binay Pradhan</a>.
  </p>
</footer>

      </div>
    </div>
  </main>
  

<script src="/blog/assets/vendor-0fb4b91f7ad6c193a69224eba7a01b691a2d7528ee672607575ccc0df3aea545.js" type="text/javascript"></script>


  <script src="/blog/assets/webfonts-96493456d319d1bf419afdf8701552d4d486fee6afd304897d4fd81eb4e0cc0b.js" type="text/javascript"></script>



  <script src="/blog/assets/scrollappear-e2da8ea567e418637e31266cc5302126eaa79f62a2273739086358b589a89ee6.js" type="text/javascript"></script>


<script src="/blog/assets/application-cfde13ac81ddaf4351b2e739603e2baf688d0fcc9aba613fe62bbb1c7b037fb9.js" type="text/javascript"></script>

</body>
</html>
